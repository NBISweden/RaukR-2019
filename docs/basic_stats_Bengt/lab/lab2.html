<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Bengt Sennblad" />


<title>Tutorial: Basic Statistics | Model estimation</title>

<script src="lab2_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="lab2_files/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="lab2_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="lab2_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="lab2_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="lab2_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="lab2_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="lab2_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="lab2_files/navigation-1.1/tabsets.js"></script>
<script src="lab2_files/navigation-1.1/codefolding.js"></script>
<link href="lab2_files/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="lab2_files/highlightjs-9.12.0/highlight.js"></script>
<link href="lab2_files/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="lab2_files/pagedtable-1.1/js/pagedtable.js"></script>
<link href="lab2_files/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="lab2_files/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link id="font-awesome-1-attachment" rel="attachment" href="lab2_files/font-awesome-5.1.0/fonts/fontawesome-webfont.ttf"/>
<script src="lab2_files/kePrint-0.0.1/kePrint.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="assets/lab.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Tutorial: Basic Statistics | <code>Model estimation</code></h1>
<h3 class="subtitle">RaukR 2019 • Advanced R for Bioinformatics</h3>
<h4 class="author">Bengt Sennblad</h4>

</div>


<p><link href="https://fonts.googleapis.com/css?family=Roboto|Source+Sans+Pro:300,400,600|Ubuntu+Mono&amp;subset=latin-ext" rel="stylesheet"></p>
<p><img src="assets/logo.svg" alt="logo_raukr" class="trlogo"></p>
<!-- ------------ Only edit title, subtitle & author above this ------------ -->
<div id="parameter-estimation-of-statistical-models" class="section level1">
<h1><span class="header-section-number">1</span> Parameter estimation of statistical models</h1>
<details>
<p><summary> Lecture notes </summary></p>
<p>Consider a generative model, with parameters <span class="math inline">\(\theta\)</span>, for how some data <span class="math inline">\(D\)</span>. We would like to test if <span class="math inline">\(\theta\)</span> are
good parameters or if some other parameters are better. Given the model, we can compute <span class="math display">\[Pr[D| \theta],\]</span> i.e., the probability that the model with parameters
<span class="math inline">\(\theta\)</span> generates <span class="math inline">\(D\)</span>.</p>
<p>However, we would be more interested in how good the model with parameters <span class="math inline">\(\theta\)</span> for our data. In other words, what we
would actually <em>like</em> to compute is <span class="math display">\[Pr[\theta|D].\]</span> This would allow us to select optimal parameter estimates and, importantly, to evaluate how good they are compared to other parameters.</p>
<p>Getting from <span class="math inline">\(Pr[D| \theta]\)</span> to <span class="math inline">\(Pr[\theta|D]\)</span> can be solved in different ways, which has given rise to two major
philosofical branches of statistics:</p>
<ul>
<li><em>Bayesian statistics</em> and</li>
<li><em>Frequentist statistics</em></li>
</ul>
</details>
<div id="bayesian-approach" class="section level2">
<h2><span class="header-section-number">1.1</span> Bayesian approach</h2>
<details>
<p><summary> Lecture notes </summary></p>
<p>Bayes’ theorem (Thomas Bayes, 1702-1761) provides a way to obtain the requested <span class="math inline">\(P[\theta|X,Y]\)</span></p>
<p><span class="math display">\[Pr[\theta|D] = \frac{Pr[D| \theta]Pr[\theta]}{Pr[D]}\]</span>
<strong>Posterior probability</strong></p>
<p><span class="math inline">\(Pr[\theta|D],\)</span> the probability, computed posterior to analysis, of the parameters <span class="math inline">\(\theta\)</span> conditioned on the observed data, i.e, our requested probability.</p>
<p>An important characteristic of Bayesian statistics is that the focus is not on point estimates, but on the posterior probability distribution over the parameter space of <span class="math inline">\(\theta\)</span>, which provides a measure of uncertainty (probabilities) in comparison to other values.</p>
<p><img src="lab2_files/figure-html/unnamed-chunk-2-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p><strong>Prior probability of <span class="math inline">\(\theta\)</span></strong></p>
<p><span class="math inline">\(Pr[\theta]\)</span> is the <em>prior</em> probability of <span class="math inline">\(\theta\)</span> and should according to Bayesian statistics reflect what we know (or believe to know) about how close <span class="math inline">\(\theta\)</span> is to the true parameters. We can use information from previous studies or we can assign a <em>uninformative</em> prior, e.g., <span class="math inline">\(Pr[\theta]\)</span> follows a uniform distribution for all <span class="math inline">\(\theta\)</span> in the interval <span class="math inline">\([a,b]\)</span>.</p>
<p>It can be shown that the effect of the prior on the posterior probsbiity is largest when the observed data is small. With larger sample sizes, the posterior probability will eventually just depend on <span class="math inline">\(Pr[D|\theta]\)</span>.</p>
<p><strong>Marginal Probability of <span class="math inline">\(D\)</span></strong></p>
<p><span class="math inline">\(Pr[D]=\int_{\theta}Pr[D| \theta]Pr[\theta]\)</span> is the probability of <span class="math inline">\(D\)</span> regardless of <span class="math inline">\(\theta\)</span>. This can often be difficult difficult to calculate and, for this reason, Bayesian models are often designed so that this can be calculated analystically or some approximation approach, such as Markov chain Monte Carlo (MCMC) is used.</p>
<details>
<p><summary> Extra reading </summary></p>
<p><strong>Probabilistic algebra</strong></p>
<p>A conditional probability <span class="math inline">\(Pr[A|B]\)</span> is the probability that <span class="math inline">\(A\)</span> happens if we know that <span class="math inline">\(B\)</span> has happened.
To obtain the probability that both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> happens we need to first take the probability that <span class="math inline">\(B\)</span> happens and then multiply it with the conditional probability that <span class="math inline">\(A\)</span> hapens given <span class="math inline">\(B\)</span>, i.e.,:</p>
<p><span class="math display">\[Pr[A,B] = Pr[A|B] Pr[B].\]</span></p>
<p>From this follows the reverse operation</p>
<p><span class="math display">\[\frac{Pr[A,B]}{Pr[B]} = Pr{A|B}\]</span>
Notice that this also works if we have more than one condition:
<span class="math inline">\(Pr[A|B,C] * Pr[B] = Pr[A,B|C].\)</span></p>
<p>What happens in Bayes rule is that we first, in the numerator, perform <span class="math inline">\(Pr[B|A]*Pr[A] = Pr[A,B]\)</span> and then divide this with the denominator <span class="math inline">\(\frac{Pr[A,B]}{Pr[B]} = Pr[A|B]\)</span>.</p>
<hr />
</details>
<hr />
</details>
</div>
<div id="likelihood" class="section level2">
<h2><span class="header-section-number">1.2</span> Likelihood – The frequentist approach</h2>
<details>
<p><summary> Lecture notes </summary></p>
<p>Likelihood (Introduced by Fisher, 1925, formalized by Edwards, 1972) builds on the intuition that if <span class="math inline">\(\theta\)</span> is close to the ‘truth’, then <span class="math inline">\(Pr[Y| X, \theta]\)</span> will be higher than for wrong <span class="math inline">\(\theta\)</span>. We should therefore select the <span class="math inline">\(\theta\)</span> that maximizes <span class="math inline">\(Pr[Y| X, \theta]\)</span>; this is called maximum likelihood estimation (MLE) of <span class="math inline">\(\theta\)</span>.</p>
<p>Since statistical model contain an element of randomness, the reasoning above might not always be correct for any single obeservation. However, if we sum over a large number of observations it will be true on average. Hence the need for datasets that are large enough.</p>
<p>To formalize this intuition, Edwards (1972) defined the likelihood of model parameters being true given observed data as</p>
<p><span class="math display">\[L[\theta|D] \propto Pr[D| \theta]\]</span></p>
<details>
<p><summary> Extra Reading </summary></p>
<p>Notice that this notation is not uncommonly mixed up, so you might also see the notation <span class="math inline">\(L[Y|X,\theta]\)</span> for the likelihood.</p>
<p>Similarly <span class="math inline">\(\propto Pr[Y|X, \theta]\)</span> is often referred to as the <em>likelihood function</em>.</p>
<hr />
</details>
<p>The proportionality (indicated by ‘<span class="math inline">\(\propto\)</span>’) means there are some unknown constant factor, <span class="math inline">\(k\)</span>, such that <span class="math inline">\(L[\theta|Y,X] = k Pr[Y|X, \theta]\)</span>. However, the factor <span class="math inline">\(k\)</span> is assumed to be constant over <span class="math inline">\(\theta\)</span>s and over models.</p>
<p>Using a Bayesian perspective, we can see that the proportionality constant <span class="math inline">\(k = \frac{Pr[\theta]}{Pr[D]}\)</span>, and that Likelihood would correspond to assuming a uniform prior over all possible values of <span class="math inline">\(\theta\)</span>.</p>
<p>In practice, the proportionality is ignored and we set</p>
<p><span class="math display">\[L[\theta|Y,X] = Pr[Y|X, \theta]\]</span></p>
<details>
<p><summary> Extra Reading </summary></p>
<p>When the likelihood of two <span class="math inline">\(\theta\)</span>s (or models) are compared this is almost always done as a <em>likelihood ratio</em>,</p>
<p><span class="math display">\[\frac{L[\theta_1|Y,X]}{L[\theta_0|Y,X]} = \frac{k Pr[Y|X, \theta_1]}{ k  Pr[Y|X, \theta_0]} =\frac{Pr[Y|X, \theta_1]}{ Pr[Y|X, \theta_0]}\]</span></p>
<p>which means that the factor <span class="math inline">\(k\)</span> disappears. Hence the factor <span class="math inline">\(k\)</span> is always ignored. Likelihood ratios is the basis of most model comparison statistics, e.g., the Wald test, the Score test, regularization…</p>
<hr />
</details>
<p>In maximum likelihood estimation of some parameters <span class="math inline">\(\theta\)</span>, one simply selects the estimates <span class="math inline">\(\widehat\theta\)</span> that gives the highest likelihood, <span class="math inline">\(max_{\theta}L[\theta|X,Y] = L[\widehat\theta|X,Y]\)</span>. In many applications of likelihood and maximum likelihood, it is practical to instead use the logarithm of the likelihood, the logLikelihood, <span class="math inline">\(\log L[\theta_1|Y,X]\)</span>.</p>
<details>
<p><summary> Extra Reading </summary></p>
<p>As mentioned above, the logarithm of the likelihood, the logLikelihood, <span class="math inline">\(\log L[\theta_1|Y,X]\)</span>, or sometimes the negative logLikelihood, <span class="math inline">\(-\log L[\theta_1|Y,X]\)</span>, is often used. Notice, that</p>
<ol style="list-style-type: decimal">
<li>The <span class="math inline">\(\theta\)</span> estimates that maximizes <span class="math inline">\(\log L[\theta|Y,X]\)</span> also maximizes <span class="math inline">\(L[\theta|Y,X]\)</span></li>
<li>The <span class="math inline">\(\theta\)</span> estimates that minimizes <span class="math inline">\(-\log L[\theta|Y,X]\)</span> maximizes <span class="math inline">\(L[\theta|Y,X]\)</span></li>
<li>A likelihood ratio corresponds to a logLikelihood difference, <span class="math display">\[\log\left(\frac{L[\theta_1|Y,X]}{L[\theta_0|Y,X]}\right) = \frac{\log L[\theta_1|Y,X]}{\log L[\theta_0|Y,X]} = \log L[\theta_1|Y,X] - \log L[\theta_0|Y,X]\]</span>.</li>
</ol>
<hr />
</details>
<p>Likelihood and maximum likelihood estimation are central concepts in frequentist statistics. Many statistical tests and methods uses or is based on the concept of maximum likelihood.</p>
<p>In general, full-on likelihood computation and maximum likelihood estimation is relatively slow, so alternative and faster methods has been developed. One example is the use <em>ordinary least squares</em> OLS for linear models; it can be shown that the likelihood can be expressed as a function of the <em>residual sum of squares</em> (RSS) and that maximum likelihood estimates of <span class="math inline">\(\beta\)</span> is exactly the same as those of the OLS (which minimizes RSS.</p>
<p><em><strong>NB!</strong> This is a special case for linear models and are not generally true for other models. For example, logistic regression is typically fitted using maximizing the likelihood </em></p>
<details>
<p><summary> Extra Reading </summary></p>
<p>Linear models is a special case with some nice properties when it comes to likelihood. Consider a simple linear regression model,</p>
<p><span class="math display">\[ y = \beta x + \epsilon, \]</span></p>
<p>where the residuals <span class="math inline">\(\epsilon\sim N(0,\sigma^2)\)</span>.</p>
<p>It turns out that the likelihood estimates of both <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> are functions of the RSS of the residuals, so that the likelihood can be approximated by</p>
<p><span class="math display">\[  \log L[\beta, \sigma^2|Y,X] \approx -\frac{N}{2} \log RSS\]</span></p>
<p>The likelihood for given <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span>, given observed data <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[ L[\beta, \sigma^2|Y,X] = \prod_i pdf_{Normal}(y_i, \mu=\beta x_i, \sigma^2=\sigma^2) = \prod_i \frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(y_i-\beta x_i)^2}{2\sigma^&quot;}} \]</span></p>
<p>where <span class="math inline">\(pdf_{Normal}\)</span> denotes the probability distribution function for the Normal distribution. If we work with the logLIkelihood instead, we get</p>
<p><span class="math display">\[\begin{eqnarray*}
\log L[\beta, \sigma^2|Y,X] 
&amp;=&amp; \sum_{i=1}^N \log\left(\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(y_i-\beta x_i)^2}{2\sigma^2}}\right)\\
&amp;=&amp;   \sum_{i=1}^N \log \left(\frac{1}{\sqrt{2\pi \sigma^2}}\right) -\frac{(y_i-\beta x_i)^2}{2\sigma^2} \\
&amp;=&amp;   N\log \left(2\pi \sigma^2\right)^{-1/2} -\frac{\sum_{i=1}^N (y_i-\beta x_i)^2}{2\sigma^2} \\
&amp;=&amp;   -\frac{N}{2}\log \left(2\pi \sigma^2\right)  -\frac{RSS}{2\sigma^2}
\end{eqnarray*}\]</span></p>
<p>We see here that minimizing <span class="math inline">\(RSS\)</span> (as in OLS) will maximize the logLikelihood, regardless of the value of <span class="math inline">\(\sigma^2\)</span>. Moreover, it turns out that also <span class="math inline">\(\sigma^2\)</span> can be estimated fairly well by <span class="math inline">\(RSS/N\)</span>. Hence, we get</p>
<p><span class="math display">\[\begin{eqnarray*}
\log L[\beta, \sigma^2|Y,X]
&amp;=&amp;   -\frac{N}{2}\log \left(\frac{2\pi RSS}{N}\right)  -\frac{N}{2}\frac{RSS}{RSS}\\
&amp;=&amp;   -\frac{N}{2}\log RSS + \frac{N}{2}\log \frac{2\pi}{N} -\frac{N}{2}\\
&amp;=&amp;   -\frac{N}{2}\log RSS + C
\end{eqnarray*}\]</span>
where <span class="math inline">\(C=\frac{N}{2}\left(\log \frac{2\pi}{N} -1\right)\)</span> is a constant that is usually ignored (in likelihood ratios, which is equivalent to log likelihoods differences, it will disappear).</p>
<hr />
</details>
<hr />
</details>
</div>
<div id="bayesians-vs-frequentists" class="section level2">
<h2><span class="header-section-number">1.3</span> Bayesians vs frequentists</h2>
<details>
<p><summary> Lecture notes </summary></p>
<p>There is often described a severe controversy between Bayesians and frequentists. However, this controversy represents the extreme hardcore Bayesians and frequentists.</p>
<p>In reality, there is a large gray-zone where frequentists and Bayesians meet and socialize:</p>
<ul>
<li>Bayesian models can be viewed as a type of the hierarchical models often used by frequentists</li>
<li>Frequentist bootstrap analysis is often used to estimate uncertainty of point estimates in relation to alternatives, as is done in Bayesian statistics</li>
<li>The <em>Bayes factor</em> is a Bayesian version of the likelihood ratio</li>
<li>Bayesian <em>posterior intervals</em> corresponds to frequentist <em>confidence intervals</em> (<em>Note</em> however, that there are no Bayesian significance test)</li>
<li>etc.</li>
</ul>
<p>Most practical statisticians use the tool that is adequate for the problem at hand, whether it is Bayesian or frequentist.</p>
<hr />
</details>
</div>
</div>
<div id="overfitting" class="section level1">
<h1><span class="header-section-number">2</span> Overfitting</h1>
<p>We will now look at a general problem in statistical modeling that can be visualized quite well with Likelihoods. We will later look at some solutions to this problem.</p>
<div id="overfitting-example-data" class="section level2">
<h2><span class="header-section-number">2.1</span> Overfitting | <code>Example data</code></h2>
<p>First, you need some test data to play around with. For simplicity and convenience, you will simulate a toy data from a linear model and use this in the exercises. The advantage for us using simulated data is that we know the ‘truth’, i.e., how the data was simulated and we therefore have <em>oracle knowledge</em> about the true parameter values, e.g., for <span class="math inline">\(\beta\)</span>.</p>
<div id="task-simulation-of-example-data" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Task | <code>simulation of example data</code></h3>
<ul>
<li>The data should comprise 100 samples.</li>
<li>First generate 10 variables <span class="math inline">\((x_1,x_2,\ldots, x_{0})\)</span> from a uniform distribution (use the function <code>runif</code>) and store them in a Matrix <span class="math inline">\(X\)</span>.</li>
<li>Use an intercept <span class="math inline">\(\beta_0=3\)</span></li>
<li>Generate effect sizes <span class="math inline">\(\beta_1, \beta_2, \beta_3\)</span> from a Uniform distribution in the interval <span class="math inline">\((0.5, 1.0)\)</span> for the 3 first <span class="math inline">\(X\)</span> variable (use the function <code>runif</code>); record the ‘true’ effect sizes for reference.</li>
<li>Finally generate outcome variable <span class="math inline">\(Y\)</span> using a linear model <span class="math inline">\(Y = \beta_0 + \beta_1 x_i + \beta_2 x_2 + \beta_3 x_3 + \epsilon\)</span>, with <span class="math inline">\(\epsilon\sim N(0,\sigma^2=1)\)</span> (i.e., the residuals are drawn from a Normal distribution with mean=0 and standard deviation=1, <em>Tip:</em> use the R function <code>rnorm</code>).</li>
</ul>
<pre class="r"><code># To obtain exactly the same result as in the demo, set seed to 85
set.seed(85)</code></pre>
<pre class="r"><code>N=100 # number of samples
P=10 # number of variables

# Draw variables, x_{i,1},...,x_{i,P} for all N individuals, from a uniform distribution in interval (0,1) (this is the default interval for runif)
X=matrix(round(runif(N*(P+1),min=0, max=2)), nrow=N, ncol=P)

# generate a y variable from a multivarite lm of 3 first X variables only
# intercept
b0=3
# effect sizes for first three variables
b=c(runif(3, min=0.5, max=1.0))

# generate y
Y = b0 + X[,1] * b[1] + X[,2] * b[2] + X[,3] * b[3] + rnorm(N)</code></pre>
</div>
</div>
<div id="overfitting-model-comparison" class="section level2">
<h2><span class="header-section-number">2.2</span> Overfitting | <code>Model comparison</code></h2>
<p>Now consider the following two linear models for our data</p>
<p><span class="math display">\[\begin{eqnarray}
y &amp; \sim &amp; \beta_0 + \beta_1 x_1 &amp; (1) \\
y &amp; \sim &amp;  \beta_0 + \beta_1 x_1 + \beta_2 x_2 &amp; (2)
\end{eqnarray}\]</span></p>
<p>What are the max Likelihood estimates of the two models? (we can use the R function <code>logLik</code> in the <code>stats</code> package)</p>
<div id="task-plot-two-likelihoods" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Task | <code>plot two likelihoods</code></h3>
<ul>
<li>Create linear models (use <code>lm</code>) for the two models, and</li>
<li>store the likelihood (use <code>logLik</code>) in a vector</li>
<li>plot the likelihoods</li>
</ul>
<pre class="r"><code>require(stats)
ll= vector()
for(i in seq(1,2)){
  Xi=X[,seq(1,i)]
  ll[i] &lt;- logLik(lm(Y~Xi))
}
# plot likelihoods for models with 1 and 2 vaiables
plot(ll, ylab=&quot;log L&quot;, xlab=&quot;model #&quot;, type = &quot;b&quot;, xlim=c(1,P), ylim=c(floor(min(ll)),ceiling(max(ll)))) 
# xlim and ylim not really necessary here, but I can reuse the plot statement below, so the plots look similar</code></pre>
<details>
<p><summary> <em>Show result</em></summary>
<img src="lab2_files/figure-html/unnamed-chunk-6-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<hr />
</details>
<p>… 2 variables are clearly better than 1 variable – What if we add more variables?</p>
</div>
<div id="task-plot-all-likelihoods" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Task | <code>plot all likelihoods</code></h3>
<ul>
<li>Now repeat this for the sequence of models obtained by creating the next model by simply adding the next <span class="math inline">\(X\)</span> variable in order.</li>
</ul>
<pre class="r"><code># compute loglikelihood (ll) for all models including variables
# 1-i, for i &lt;= P; store results in vector ll
ll= vector()
for(i in seq(1,P)){
  Xi=X[,seq(1,i)]
  ll[i] &lt;- logLik(lm(Y~Xi))
}

# plot ll for all models
plot(ll, ylab=&quot;log L&quot;, xlab=&quot;model #&quot;, type = &quot;b&quot;, xlim=c(1,P), ylim=c(floor(min(ll)),ceiling(max(ll)))) </code></pre>
<details>
<p><summary> <em>Show result</em></summary>
<img src="lab2_files/figure-html/unnamed-chunk-8-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<hr />
</details>
<div id="think-about" class="section level4">
<h4><span class="header-section-number">2.2.2.1</span> Think about:</h4>
<ul>
<li><p>How does the Likelihood behave as more variables are added?</p></li>
<li><p>Which is the maximum likelihood model? Is this correct given our <em>oracle knowledge</em>?</p></li>
<li><p>What could be the problem with this behaviour? How would we like it to behave?</p></li>
<li><p>How can we obtain the desired behaviour?</p></li>
</ul>
<details>
<summary> Some possible answers </summary>
<h4>
Some possible answers
</h4>
<p><em>Nested models</em></p>
<ul>
<li><p>Model (1) can be described as a special case of Model (2) with the constraints on <span class="math inline">\(\beta_2=0\)</span></p></li>
<li><p>Therefore Model (2) will always have equal or better ML than Model (1)</p></li>
<li><p>We say that model (1) is nested in Model (2) (which is nested in Model (3) etc.)</p></li>
</ul>
<p><em>Overfitting</em></p>
<ul>
<li>Using our <em>oracle knowledge</em>, we know that the simulated data was generated from the 3 first variables
<ul>
<li>thus, the subsequent variables increase ML by modeling noise in data</li>
</ul></li>
<li><p>This is difficult to detect by just looking at the likelihoods</p></li>
<li>Solutions
<ul>
<li>Seek the simplest model that is “good enough” -&gt; Regularization/Bayesian</li>
</ul></li>
</ul>
<hr />
</details>
<details>
<summary> Extra Reading </summary>
<h2>
Model comparison | <code>Likelihood ratio test</code>
</h1>
<p><em>(Read <strong>Extra reading</strong> about likelihood ratios under <a href="#likelihood">1.2</a> first)</em>
For nested models <span class="math inline">\(-2 \max LRT\)</span> is <span class="math inline">\(\chi^2(d)\)</span>-distributed, with <span class="math inline">\(d=\)</span> the difference in free params in the two models.</p>
<table class="table table-striped" style="font-size: 14px; width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Compared models
</th>
<th style="text-align:right;">
logL 1st model
</th>
<th style="text-align:right;">
logL 2nd model
</th>
<th style="text-align:left;">
logLR
</th>
<th style="text-align:left;">
P-value
</th>
<th style="text-align:left;">
Sign at 0.05
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1 vs 2 variables
</td>
<td style="text-align:right;">
-155.80
</td>
<td style="text-align:right;">
-146.90
</td>
<td style="text-align:left;">
-8.9
</td>
<td style="text-align:left;">
2.45e-05
</td>
<td style="text-align:left;">
yes
</td>
</tr>
<tr>
<td style="text-align:left;">
2 vs 3 variables
</td>
<td style="text-align:right;">
-146.90
</td>
<td style="text-align:right;">
-136.73
</td>
<td style="text-align:left;">
-10.17
</td>
<td style="text-align:left;">
6.48e-06
</td>
<td style="text-align:left;">
yes
</td>
</tr>
<tr>
<td style="text-align:left;">
3 vs 4 variables
</td>
<td style="text-align:right;">
-136.73
</td>
<td style="text-align:right;">
-136.69
</td>
<td style="text-align:left;">
-0.04215
</td>
<td style="text-align:left;">
0.772
</td>
<td style="text-align:left;">
no
</td>
</tr>
<tr>
<td style="text-align:left;">
4 vs 5 variables
</td>
<td style="text-align:right;">
-136.69
</td>
<td style="text-align:right;">
-136.23
</td>
<td style="text-align:left;">
-0.4601
</td>
<td style="text-align:left;">
0.337
</td>
<td style="text-align:left;">
no
</td>
</tr>
<tr>
<td style="text-align:left;">
5 vs 6 variables
</td>
<td style="text-align:right;">
-136.23
</td>
<td style="text-align:right;">
-135.83
</td>
<td style="text-align:left;">
-0.4016
</td>
<td style="text-align:left;">
0.37
</td>
<td style="text-align:left;">
no
</td>
</tr>
<tr>
<td style="text-align:left;">
6 vs 7 variables
</td>
<td style="text-align:right;">
-135.83
</td>
<td style="text-align:right;">
-135.35
</td>
<td style="text-align:left;">
-0.4803
</td>
<td style="text-align:left;">
0.327
</td>
<td style="text-align:left;">
no
</td>
</tr>
<tr>
<td style="text-align:left;">
7 vs 8 variables
</td>
<td style="text-align:right;">
-135.35
</td>
<td style="text-align:right;">
-135.31
</td>
<td style="text-align:left;">
-0.04266
</td>
<td style="text-align:left;">
0.77
</td>
<td style="text-align:left;">
no
</td>
</tr>
<tr>
<td style="text-align:left;">
8 vs 9 variables
</td>
<td style="text-align:right;">
-135.31
</td>
<td style="text-align:right;">
-135.30
</td>
<td style="text-align:left;">
-0.0002981
</td>
<td style="text-align:left;">
0.981
</td>
<td style="text-align:left;">
no
</td>
</tr>
<tr>
<td style="text-align:left;">
9 vs 10 variables
</td>
<td style="text-align:right;">
-135.30
</td>
<td style="text-align:right;">
-134.55
</td>
<td style="text-align:left;">
-0.7536
</td>
<td style="text-align:left;">
0.22
</td>
<td style="text-align:left;">
no
</td>
</tr>
</tbody>
</table>
<p>In our simple test case, the LRT also succeed in picking the correct model. It should be noted that certain issues, such as <em>lnkage disequilibriium</em>, may cause problems for LRT (<em>the example is not optimized to show this</em>).</p>
<hr />
</details>
</div>
</div>
</div>
</div>
<div id="regularization" class="section level1">
<h1><span class="header-section-number">3</span> Regularization</h1>
<details>
<p><summary> Lecture notes </summary></p>
<p>Regularization is a concept that adds auxiliary criteria, so-called <em>regularization terms</em>, to probabilistic models. This is called regularized likelihood models or penalized likelihood models. Typically, the regularization term is a function of parameters <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[\log rL[\beta | X, Y]  = \log Pr[Y | X, \beta] - f(\beta),\]</span></p>
<p>A very simple regularized likelihood model uses <span class="math inline">\(f(\beta) = \#\beta = \#X\)</span>, that is the number of <span class="math inline">\(X\)</span> variables.<br />
<span class="math display">\[\log rL[{\beta} | X, Y]  = \log Pr[Y | X, {\beta}] - \#X, \]</span></p>
<p>Applying this rL to our example data, solves the overfitting problem.</p>
<pre class="r"><code># compute loglikelihood (ll) for all models including 1-P variables
pl= vector() 
for(i in seq(1,P)){
  xi=X[,seq(1,i)]
  xi=cbind(rep(1,N), xi)
  fit = lm(Y~xi)
  # To make the code simple, we forestall next step and use the AIC function here
  # AIC= -2(pl) so convert back
  pl[i] = -AIC(fit)/2
}
# plot ll of all models
plot(pl, xlim=c(1,P), ylim=c(floor(min(pl)),ceiling(max(pl))),ylab=&quot;log pL&quot;, xlab=&quot;model #&quot;, type = &quot;b&quot;)</code></pre>
<p><img src="lab2_files/figure-html/unnamed-chunk-9-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
</details>
<div id="regularization-bayesian-interpretation" class="section level2">
<h2><span class="header-section-number">3.1</span> Regularization | <code>Bayesian interpretation</code></h2>
<details>
<p><summary> Lecture notes </summary></p>
<p>Regularization is a canonical example where Bayesian and frequentist statistics meet.</p>
<p>The standard way of writing a regularized likelihood is using the logLikelihood, but what if ‘de-log’ it:</p>
<p><span class="math display">\[\begin{eqnarray*}
\log rL[\beta | X, Y]  &amp;=&amp; \log Pr[Y | X, \beta] - f(\beta) \\
\Downarrow\\
rL[\beta | X, Y]  &amp;=&amp; Pr[Y | X, \beta] * e^{- f(\beta)}
\end{eqnarray*}\]</span></p>
<p>This looks suspiciously like an un-normalized posterior probability (i.e., lacking the denominator), with an exponential prior <span class="math inline">\(Pr[\beta]=e^{-f(\beta)}.\)</span></p>
<p>As we will see examples of, most regularization techniques have a Bayesian interpretation.</p>
<p>In fact, a standard solution overfitting and, more generally, over-parameterization, i.e., problems where the likelihood function may not have a unique maximmum, is to include prior information, either as Bayesian priors or regularization terms to limit the parameter space. This is an area where Bayesian and frequentist socialize and get on well.</p>
</details>
</div>
<div id="regularization-aic-and-model-testing" class="section level2">
<h2><span class="header-section-number">3.2</span> Regularization | <code>AIC and model testing</code></h2>
<details>
<p><summary> Lecture notes </summary></p>
<p>Coming from a <em>information theory</em> base, Hirotugu Akaike (1974) came up with a very similar approach for solving the overfitting problem.</p>
<p>The Akaike information criterion (AIC), for a model <span class="math inline">\(m\)</span> with variables <span class="math inline">\(X\)</span>, is defined as</p>
<p><span class="math display">\[AIC_m = 2\# X - 2\log \max L[{\beta}|X,Y]\]</span></p>
<p>We see that <span class="math inline">\(AIC_m = -2 \left(\log \max L[{\beta}|X,Y] - \#X\right)\)</span>, i.e., <span class="math inline">\(-2\)</span> times the the simple <span class="math inline">\(\log rL\)</span>, we just looked at in our first regularization example.</p>
<p>In the information theory context, the difference in <span class="math inline">\(AIC\)</span> between two models is claimed to estimate the information lost by selecting the worse model.</p>
<p>Sometimes, the <em>relative likelihood</em> for model <span class="math inline">\(m\)</span> is used, which is
<span class="math display">\[relL = e^\frac{ AIC_{min} - AIC_{m} }{2}\]</span>
where <span class="math inline">\(AIC_{min}\)</span> is the minimum AIC among a set of compared models</p>
<details>
<p><summary> Extra Reading </summary></p>
<ul>
<li><p><span class="math inline">\(relL\)</span> can be interpreted as proportional to the probability that the model <span class="math inline">\(m\)</span> minimizes the information loss.
<!--       and can be interpreted as -->
<!-- $rL \propto Pr[m\textrm{ minimizes estimated information loss}]$. --></p>
<ul>
<li>Notice that<span class="math display">\[ relL = \frac{e^{\#X_m} }{e^{\#X_{min}}}\frac{\max L[{\beta}_{m}|X_m,Y]}{\max L[{\beta}_{min}|X_{min},Y]}\]</span>
we see that <span class="math inline">\(rL\)</span> can be viewed as a weighted likelihood ratio or maybe more naturally as a Bayes factor</li>
</ul></li>
</ul>
<hr />
</details>
</details>
<div id="task-aic-analysis" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Task | <code>AIC analysis</code></h3>
<ul>
<li><p>A typical AIC analyss strategy is to select the model, <span class="math inline">\(m\)</span> with <span class="math inline">\(AIC_m=AIC_{min}\)</span> and then evaluate how much better it is than the other candidate models, e.g., using the <span class="math inline">\(relL\)</span>.</p></li>
<li>Apply this AIC strategy applied to our example data using the R funcion <code>AIC</code></li>
<li><p>create a table with the AIC and the <span class="math inline">\(relL\)</span> for the set of models comprising <span class="math inline">\(\{X_1, .\ldots, X_i\} \textrm{ for } i \in [1, \ldots, 10]\)</span>; indicate also if a model is the minimum AIC model.</p></li>
</ul>
<pre class="r"><code>require(stats) 
require(dplyr)      # used for nice table formatting
require(kableExtra) # used for nice table formatting

mprev &lt;- lm(Y ~ X[,1]) # current miminimum AIC model
# dummyentry to be replaced
aic=data.frame(models=0, aic=0, isAICmin=&quot;-&quot;) 

for(i in seq(2,P)){
  m &lt;- lm(Y ~ X[,seq(1,i)])
  fit = AIC(mprev,m) # compare with current the minimum model
  mprev = m
  if(i==2){ #include also the first model
    aic[i-1,] = list(paste0(i-1,&quot; variable&quot;), signif(fit$AIC[1],5), &quot;-&quot;) 
  }
  aic[i,] = list(paste0(i,&quot; variables&quot;), signif(fit$AIC[2],5), &quot;-&quot;) 
}
minaic=min(aic$aic)
aic$rl=format(exp((minaic-aic$aic)/2), digits=4)
aic$isAICmin = ifelse(aic$aic==minaic,&quot;Yes&quot;,&quot;-&quot;)

kable(aic, format=&#39;html&#39;, row.names=F, col.names=c(&quot;Compared models&quot;,&quot;AIC&quot;,&quot;Minimum AIC&quot;,&quot;rL&quot;),digits=30,format.args=list(snsmall=0))  %&gt;%  kable_styling( font_size = 14)</code></pre>
<details>
<summary> <em>Show result</em></summary>
<table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Compared models
</th>
<th style="text-align:right;">
AIC
</th>
<th style="text-align:left;">
Minimum AIC
</th>
<th style="text-align:left;">
rL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1 variable
</td>
<td style="text-align:right;">
317.61
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
3.841e-08
</td>
</tr>
<tr>
<td style="text-align:left;">
2 variables
</td>
<td style="text-align:right;">
301.80
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
1.041e-04
</td>
</tr>
<tr>
<td style="text-align:left;">
3 variables
</td>
<td style="text-align:right;">
283.46
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
1.000e+00
</td>
</tr>
<tr>
<td style="text-align:left;">
4 variables
</td>
<td style="text-align:right;">
285.38
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
3.829e-01
</td>
</tr>
<tr>
<td style="text-align:left;">
5 variables
</td>
<td style="text-align:right;">
286.46
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
2.231e-01
</td>
</tr>
<tr>
<td style="text-align:left;">
6 variables
</td>
<td style="text-align:right;">
287.66
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
1.225e-01
</td>
</tr>
<tr>
<td style="text-align:left;">
7 variables
</td>
<td style="text-align:right;">
288.70
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
7.280e-02
</td>
</tr>
<tr>
<td style="text-align:left;">
8 variables
</td>
<td style="text-align:right;">
290.61
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
2.802e-02
</td>
</tr>
<tr>
<td style="text-align:left;">
9 variables
</td>
<td style="text-align:right;">
292.61
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
1.031e-02
</td>
</tr>
<tr>
<td style="text-align:left;">
10 variables
</td>
<td style="text-align:right;">
293.10
</td>
<td style="text-align:left;">
<ul>
<li></td>
<td style="text-align:left;">
8.067e-03
</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<hr />
</details>
<ul>
<li>Try to plot the <span class="math inline">\(AIC\)</span> and the <span class="math inline">\(reL\)</span> with the different models on the <span class="math inline">\(X\)</span>-axis</li>
</ul>
<pre class="r"><code>require(stats)

# plot AIC of all models
plot(aic$aic, xlim=c(1,P), ylim=c(floor(min(aic$aic)),ceiling(max(aic$aic))),ylab=&quot;AIC&quot;, xlab=&quot;model #&quot;, type = &quot;b&quot;)

# plot relL of all models
plot(aic$rl, xlim=c(1,P), ylab=&quot;relL&quot;, xlab=&quot;model #&quot;, type = &quot;b&quot;)</code></pre>
<details>
<p><summary> <em>Show result</em></summary>
<img src="lab2_files/figure-html/unnamed-chunk-13-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /><img src="lab2_files/figure-html/unnamed-chunk-13-2.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<hr />
</details>
<div id="think-about-1" class="section level4">
<h4><span class="header-section-number">3.2.1.1</span> Think about:</h4>
<ul>
<li>Which is the best model? Is this correct compared to our <em>oracle knowledge</em>?</li>
<li>How good is it compared to the others?</li>
<li>Can you see a drawback in our model testing approach above? If so, how can we solve that?</li>
</ul>
<details>
<summary> Some possible answers </summary>
<h4>
Some possible answers
</h4>
<ul>
<li>We see that the best model is the one with the 3 first X-variables (in line with our <em>oracle knowledge</em>) and that the second best model (with the first 4 X-variabels) is <span class="math inline">\(\approx 60\%\)</span> as good.</li>
</ul>
<details>
<p><summary> Extra Reading </summary></p>
<ul>
<li>Sometimes it is desirable to compute a significance for rejecting a model in favour of another model. A NULL distribution for the <span class="math inline">\(relL\)</span> statistic is usally obtained through simulation, e.g., using parameteric bootstrapping.</li>
</ul>
<hr />
</details>
<ul>
<li>Now, I this case we happened to know that the first 3 variables was the right one, so the order we choose to include them was correct. However, in the general case, we do not know this. How solve this?
<ul>
<li>Best subset method; involves testing all possible subsets, which is computationally time-consuming and sometimes unfeasible</li>
<li>Lasso</li>
</ul></li>
</ul>
<hr />
</details>
</div>
</div>
</div>
<div id="regularization-lasso-and-feature-selection" class="section level2">
<h2><span class="header-section-number">3.3</span> Regularization | <code>LASSO and Feature selection</code></h2>
<details>
<p><summary> Lecture notes </summary></p>
<p>LASSO stands for Least absolute shrinkage and selection operator (“shrinkage” is another common term for regularization) and is a method for selecting variables to include in a multivariate model.</p>
<p>Classical LASSO builds on RSS of a linear regression model <span class="math inline">\(Y \sim X{\beta}\)</span> with regularization</p>
<details>
<p><summary> Extra Reading </summary></p>
<p>Extensions to glms exists, but then using a regularized likelihood expression</p>
<hr />
</details>
<p>The regularization term <span class="math inline">\(f(\beta) = \lambda\sum_{\beta_i\in\beta} |\beta_i-0|= \lambda\sum_{\beta_i\in\beta} |\beta_i|\)</span></p>
<p>The <span class="math inline">\(\lambda\)</span> parameter sets a limit on the estimation of <span class="math inline">\(\beta\)</span>.</p>
<p>Lasso is traditionally described as RSS with an auxiliary criterion/constraint:</p>
<p><span class="math display">\[min_{{\beta}}\left\{RSS\right\} + \lambda\sum_{\beta_i\in\beta} |\beta_i|.\]</span>
Lasso can also be viewed as a un-normalized Bayesian posterior probability, with a LaPlacean prior on <span class="math inline">\(\beta\)</span>: <span class="math inline">\(\beta_j ∼ LaPlace(0, 1/\lambda)\)</span></p>
<details>
<p><summary> Extra Reading </summary>
Often the regularization term is expressed in terms of the <span class="math inline">\(\ell_1-norm\)</span>, which can be viewed simply a short-hand notation, e.g., the <span class="math inline">\(\ell_1-norm\)</span> of <span class="math inline">\(\beta\)</span> is
<span class="math display">\[ ||\beta||_1 = \sum_{\beta_i\in\beta} |\beta_i|\]</span></p>
<p>There is also a <span class="math inline">\(\ell_2-norm\)</span>:
<span class="math display">\[ ||\beta||_2 = \sqrt{\sum_{\beta_i\in{\beta}} \beta_i^2}\]</span>
which is used, e.g., in ridge regression. This correspond to a Normal prior for Baysians.</p>
<p>We note, BTW, that you might already have encountered an <span class="math inline">\(\ell_2-norm\)</span>: since <span class="math inline">\(RSS = ||Y-X\beta||_2^2\)</span> is simply the square of the <span class="math inline">\(\ell_2\)</span> norm of the residuals.</p>
<ul>
<li>You might also see the notation <span class="math display">\[min_{{\beta}}\left\{RSS\right\} \textrm{ subject to } ||{\beta}||_1 &lt;= t\]</span>
where <span class="math inline">\(t\)</span> is related to <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<hr />
</details>
<p>The optimal values of <span class="math inline">\(\beta\)</span> for different values of <span class="math inline">\(\lambda\)</span> are then estimated, using some algorithm (lars or coordinate descent). A convenient way to think about this is that at very high <span class="math inline">\(\lambda\)</span> values, all <span class="math inline">\(\beta_s\)</span> are 0; by sequentially lowering <span class="math inline">\(\lambda\)</span> more and more <span class="math inline">\(\beta_i\)</span> become non-zero, the most important variables <span class="math inline">\(i\)</span> are included first.</p>
<details>
<p><summary> Extra Reading </summary></p>
<p>The <em>Coordinate descent</em> algorithm is used in the R package <code>glmnet</code>:</p>
<ol style="list-style-type: decimal">
<li>Over a grid of <span class="math inline">\(\lambda\in [0, \infty]\)</span>, do
<ol style="list-style-type: decimal">
<li>Start with all <span class="math inline">\(\beta=0\)</span></li>
<li>until convergence repeat for each <span class="math inline">\(\beta_i\)</span>
<ol style="list-style-type: decimal">
<li>while keeping all other <span class="math inline">\(\beta\)</span> fixed and <span class="math inline">\(\beta_i=0\)</span>, compute partial residuals</li>
<li>estimate <span class="math inline">\(\beta_i\)</span> by RSS on the partial residuals</li>
<li>update $_i using the RSS estimate and <span class="math inline">\(\lambda\)</span>.</li>
</ol></li>
</ol></li>
</ol>
<hr />
</details>
<details>
<p><summary> Extra Reading </summary></p>
<p>Alternatives to LASSO, differing mainly in the auxiliary criterion</p>
<ul>
<li><em>Ridge regression</em> which uses a <span class="math inline">\(\ell_2\)</span> norm</li>
<li><em>Elastic-net</em>, which uses a mixed model combination of the <span class="math inline">\(\ell_1\)</span> norm and the <span class="math inline">\(\ell_2\)</span> norm.</li>
</ul>
<hr />
</details>
</details>
<div id="task-lasso-using-the-glmnet-r-package" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Task | <code>Lasso using the glmnet R-package</code></h3>
<ul>
<li>Use function <code>glmnet</code> to perform LASSO analysis on our example data; relevant arguments of the function include:
<ul>
<li>linear regression (<code>family='gaussian'</code> = default)</li>
<li>LASSO (<code>alpha=1</code> = default)</li>
<li>standardization
<ul>
<li>The variables Y and X must be centered and standardized to ensure that all variables are given equal weight in the model selection.</li>
<li>standardization of <span class="math inline">\(X\)</span> to unit variance in <code>glmnet</code> is obtained by setting the argument <code>standardize=TRUE</code> which is the default</li>
<li>the values of <span class="math inline">\(Y\)</span> is always standardized (?) for <code>family=gaussian</code> (LASSO)</li>
<li>and the coefficients are back-standardized before reported</li>
</ul></li>
</ul></li>
</ul>
<details>
<p><summary> Extra Reading </summary></p>
<p>Standardization in <code>glmnet</code>:</p>
<ul>
<li><span class="math inline">\(x&#39; = \frac{x-\bar{x}}{s/\sqrt{N}}\)</span>
where <span class="math inline">\(\frac{s}{\sqrt{N}}\)</span> is the estimate of the standard deviation of <span class="math inline">\(x\)</span> (and, incidently, can be written using the <span class="math inline">\(\ell_2-\)</span>norm: <span class="math inline">\(\frac{s}{\sqrt{N}} = \frac{\sum_{x_i \in x} (x-\bar{x})^2}{\sqrt{N}} = \frac{||X-\bar{x}||_2}{\sqrt{N}}\)</span>).</li>
</ul>
<hr />
</details>
<pre class="r"><code>require(glmnet)
# run lasso (alpha=1) for linear model (family=gaussian)
fit = glmnet(X,Y, family=&quot;gaussian&quot;, alpha=1, standardize=T)</code></pre>
<ul>
<li>A graphical way to view the result is to <code>plot</code> the paths of <span class="math inline">\(\beta\)</span> for increasing vaules of <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<pre class="r"><code>plot(fit, xvar=&quot;lambda&quot;,label=T)</code></pre>
<details>
<p><summary> <em>Show result</em></summary>
<img src="lab2_files/figure-html/unnamed-chunk-16-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<hr />
</details>
<div id="think-about-2" class="section level4">
<h4><span class="header-section-number">3.3.1.1</span> Think about</h4>
<ul>
<li>In which order are variables included (i.e., their <span class="math inline">\(\beta\)</span> becomes non-zero)?</li>
<li>In which direction is the effect</li>
<li>Which lambda should we select?
<ul>
<li>Given our <em>oracle knowledge</em>, where would an appropriate <span class="math inline">\(\lambda\)</span> be?</li>
<li>Can we use that?</li>
</ul></li>
</ul>
<details>
<p><summary> Some possible answers </summary></p>
<h4>
Some possible answers
</h4>
<ul>
<li>The order in the above plot appears to be <span class="math inline">\((1,2,3,7,6,5,10,9,4,8)\)</span> (may vary depending on the simulation)</li>
<li><span class="math inline">\(\beta_i &gt; 0, i\in \{1,2,3,4,7,9\}\)</span>, while <span class="math inline">\(\beta_i&lt;0, i\in \{5,6,8,10\}\)</span></li>
<li>Given <em>oracle knowledge</em>, the correct <span class="math inline">\(\lambda\)</span> appears lie somewhere in the interval <span class="math inline">\([\approx \exp(-0.9), \approx\exp(-2.25)]\)</span></li>
<li>In the typical analysis case, we never have <em>oracle knowledge</em>.</li>
</ul>
<hr />
</details>
</div>
</div>
</div>
<div id="cross-validation" class="section level2">
<h2><span class="header-section-number">3.4</span> Cross-validation</h2>
<details>
<p><summary> Lecture notes </summary></p>
<p>The LASSO model will be different depending on how we set <span class="math inline">\(\lambda\)</span>. A problem is to decide the optimal <span class="math inline">\(\lambda\)</span> to use.</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> too <em>high</em>: risk of missing relevant variables</li>
<li><span class="math inline">\(\lambda\)</span> too <em>low</em>: risk of overfitting</li>
</ul>
<p><code>glmnet</code> addresses this using <em><span class="math inline">\(k\)</span>-fold cross-validation</em> – what is that?</p>
</details>
<div id="cross-validation-how-to-test-for-overfitting" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Cross-validation | <code>How to test for overfitting</code></h3>
<details>
<p><summary> Lecture notes </summary></p>
<p>The ultimate way of testing an estimated model (with parameters) is to apply it to new data and evaluate how well it performs, e.g., by measuring the <em>mean squared error</em>, <span class="math inline">\(MSE\)</span> (<span class="math inline">\(=RSS/N\)</span>).
Naturally, we want to minimize <span class="math inline">\(MSE\)</span>, i.e., the error of the model. In our LASSO application, this means that we want to select the <span class="math inline">\(\lambda\)</span> that minimizes the <span class="math inline">\(MSE\)</span></p>
<p>In cross validation, this approach is emulated by partioning the data at hand into a <em>training</em> and a <em>validation</em> data set. The model parameters are estimated (‘trained’) on the the training data and the validated on the test data.</p>
<p>By chance, this may fail if the partitioning is ‘non-representative’. A solution is to repeat the cross-validation procedure with another partioning.</p>
<p>In <span class="math inline">\(k\)</span>-fold cross validation, the original data is split into <span class="math inline">\(k\)</span> sub-datasets <span class="math inline">\(\{D_1,D_2,\ldots, D_k\}\)</span>.
For <span class="math inline">\(i \in \{1,2,\ldots, k\}\)</span>, set <span class="math inline">\(D_i\)</span> as the test data set and the union of the other datasets be the training data. Perform cross validation as above.</p>
<p>This gives a distribution of <span class="math inline">\(MSE\)</span> from which we can estimate, e.g., mean and standard deviation.</p>
<details>
<p><summary>Additional reading</summary></p>
<p>This distribution allows us to use more elaborate means to select <span class="math inline">\(\lambda\)</span>. One common suggestion is to use the largest <span class="math inline">\(\lambda\)</span> whose <span class="math inline">\(MSE\)</span> is within 1 standard error from the minimum value (called <code>lambda.1se</code> in <code>glmnet</code>). The motivation argued for this choice is <em>parsimony</em>, in the sense that larger <span class="math inline">\(\lambda\)</span> will include fewer variables (hence it is parsimonious in terms of number of included variables).</p>
<p>Here we will limit ourselves to finding the minimum <span class="math inline">\(\lambda\)</span>, called <code>lambda.min</code> in <code>glmnet</code>, but anyone is free to test if <code>lambda.1se</code> gives a different result.</p>
<hr />
</details>
</details>
</div>
<div id="task-determine-optimal-lassolambdausing-cross-validation" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Task | <code>Determine optimal LASSO</code><span class="math inline">\(\lambda\)</span><code>using cross-validation</code></h3>
<ul>
<li>Use the function <code>cv.glmnet</code> to perform cross validation (same options as for <code>glmnet</code>)</li>
<li><code>plot</code> the cross-validation results</li>
<li>Compare with the plot of estimated <span class="math inline">\(\beta_i\)</span> under different <span class="math inline">\(\lambda\)</span>.</li>
<li>Determine the optimal <span class="math inline">\(\lambda\)</span> (the one with minimal error)</li>
</ul>
<pre class="r"><code>require(glmnet)
par(mfrow=c(1,1))
# run lasso (alpha=1) for linear model (family=gaussian)
cvglm=cv.glmnet(X,Y, family=&quot;gaussian&quot;, alpha=1, standardize=T, nfolds=100)

plot(cvglm)
plot(cvglm$glmnet.fit, xvar=&quot;lambda&quot;,label=T)
minlambda=cvglm$lambda.min</code></pre>
<details>
<p><summary> <em>Show result</em></summary>
<img src="lab2_files/figure-html/unnamed-chunk-18-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /><img src="lab2_files/figure-html/unnamed-chunk-18-2.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<hr />
</details>
<div id="think-about-3" class="section level4">
<h4><span class="header-section-number">3.4.2.1</span> Think about</h4>
<ul>
<li>Which is the <span class="math inline">\(\lambda\)</span> selected by <code>cv.glmnet</code>?</li>
<li>Does this make sense given our <em>oracle knowledge</em>?</li>
</ul>
<details>
<p><summary> Some possible answers </summary></p>
<h4>
Some possible answers
</h4>
<ul>
<li>Cross-validation-selected optimal <span class="math inline">\(\lambda\)</span> is 0.1064891 (<span class="math inline">\(log \lambda=\)</span>-2.2397124)</li>
<li>Yes, this includes only the <em>oracle knowledge</em> correct variables <span class="math inline">\(X_1, X_2, X_3\)</span></li>
</ul>
<hr />
</details>
</div>
</div>
<div id="task-final-lasso-effect-sizes" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Task| <code>Final LASSO effect sizes</code></h3>
<ul>
<li>Finally print a table with the <span class="math inline">\(\beta\)</span> coefficients (including the intercept, <span class="math inline">\(\beta_0\)</span>) for the optimal model (i.e., at minimum <span class="math inline">\(\lambda\)</span>). (Use function<code>coef</code>).</li>
</ul>
<pre class="r"><code># Actually the following suffice for output on console
#coef(cvglm, s=&quot;lambda.min&quot;)

# But to get a nice table:
require(dplyr)      # for nice table
require(kableExtra) #for nice table

coefglm=as.data.frame(as.matrix(coef(cvglm, s=&quot;lambda.min&quot;)))
coefglm=cbind(seq(0,10),c(b0, b, rep(0, 7)),coefglm)
names(coefglm)=c(&quot;beta&quot;,&quot;value (oracle)&quot;, paste0(&quot;estimate(lambda=&quot;,signif(minlambda,3),&quot;)&quot;))
kable(coefglm, row.names=F) %&gt;%   kable_styling( font_size = 14)</code></pre>
<details>
<p><summary> <em>Show result</em></summary></p>
<table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
beta
</th>
<th style="text-align:right;">
value (oracle)
</th>
<th style="text-align:right;">
estimate(lambda=0.106)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3.0000000
</td>
<td style="text-align:right;">
3.6046135
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.8125118
</td>
<td style="text-align:right;">
0.5905522
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.6009469
</td>
<td style="text-align:right;">
0.4631531
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0.7232911
</td>
<td style="text-align:right;">
0.5204561
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
</tbody>
</table>
<hr />
</details>
<div id="think-about-4" class="section level4">
<h4><span class="header-section-number">3.4.3.1</span> Think about</h4>
<ul>
<li>Does the effect sizes make sense – if not can you think of why?</li>
</ul>
<details>
<summary> Some possible answers </summary>
<h4>
Some possible answers
</h4>
<ul>
<li>Well…yes… sort of!
<ul>
<li><span class="math inline">\(\beta_i\)</span> is non-zero only for <em>oracle</em>-known variables <span class="math inline">\(X_1, X_2, X_3\)</span></li>
<li><em>however</em>,they don’t exactly equate our <em>oracle knowledge</em> parameter values – they appear to be scaled.</li>
<li><em>but</em> their relative order of amplitude is right.</li>
</ul></li>
<li>Perhaps the normalization affected scaling.</li>
</ul>
<!-- --------------------- Do not edit this and below ---------------------- -->
</div>
</div>
</div>
</div>
<div id="session-info" class="section level1">
<h1><span class="header-section-number">4</span> Session info</h1>
<pre><code>## R version 3.5.3 (2019-03-11)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] igraph_1.2.4.1   glmnet_2.0-18    foreach_1.4.4    Matrix_1.2-17   
##  [5] dplyr_0.8.1      kableExtra_1.1.0 lmtest_0.9-37    zoo_1.8-6       
##  [9] captioner_2.2.3  bookdown_0.11    knitr_1.23      
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.1         lattice_0.20-38    prettyunits_1.0.2 
##  [4] ps_1.3.0           assertthat_0.2.1   digest_0.6.19     
##  [7] packrat_0.5.0      mime_0.6           plyr_1.8.4        
## [10] R6_2.4.0           stats4_3.5.3       evaluate_0.14     
## [13] ggplot2_3.1.1      httr_1.4.0         xaringan_0.10     
## [16] highr_0.8          pillar_1.4.1       rlang_0.3.4       
## [19] lazyeval_0.2.2     rstudioapi_0.10    callr_3.2.0       
## [22] rmarkdown_1.13     webshot_0.5.1      servr_0.13        
## [25] readr_1.3.1        stringr_1.4.0      loo_2.1.0         
## [28] munsell_0.5.0      compiler_3.5.3     httpuv_1.5.1      
## [31] xfun_0.7           rstan_2.18.2       pkgconfig_2.0.2   
## [34] pkgbuild_1.0.3     htmltools_0.3.6    tidyselect_0.2.5  
## [37] tibble_2.1.3       gridExtra_2.3      matrixStats_0.54.0
## [40] codetools_0.2-16   viridisLite_0.3.0  crayon_1.3.4      
## [43] later_0.8.0        grid_3.5.3         jsonlite_1.6      
## [46] gtable_0.3.0       magrittr_1.5       StanHeaders_2.18.1
## [49] scales_1.0.0       cli_1.1.0          stringi_1.4.3     
## [52] promises_1.0.1     xml2_1.2.0         iterators_1.0.10  
## [55] tools_3.5.3        glue_1.3.1         purrr_0.3.2       
## [58] hms_0.4.2          parallel_3.5.3     rsconnect_0.8.13  
## [61] processx_3.3.1     yaml_2.2.0         inline_0.3.15     
## [64] colorspace_1.4-1   rvest_0.3.4</code></pre>
<p style="text-align: left; font-size: small;">
Built on: <i class="fa fa-calendar" aria-hidden="true"></i> 13-Jun-2019 at <i class="fa fa-clock-o" aria-hidden="true"></i> 11:19:47.
</p>
<hr/>
<div style="padding-bottom: 1.5em">
<p><span style="float:left; vertical-align:middle">
<b>2019</b> • <a href="https://www.scilifelab.se/">SciLifeLab</a> • <a href="https://nbis.se/">NBIS</a> • <a href="https://nbisweden.github.io/workshop-RaukR-1906/">RaukR</a>
</span>
<span style="float:right; vertical-align:middle">
<span class="footericon" style="padding-right:4px; padding-left:4px">
<a href="https://nbisweden.github.io/workshop-RaukR-1806/"><img src="assets/icons8-globe-26.png" alt="website" border="0" style="height:15px"></a>
</span>
<span class="footericon" style="padding-right:4px; padding-left:4px">
<a href="https://twitter.com/hashtag/RaukR?src=hash"><img src="assets/icons8-twitter-26.png" alt="twitter" border="0" style="height:15px"></a>
</span>
</span></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
